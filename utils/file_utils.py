"""
File and directory utilities for YOLOv8 training project
"""

import os
import shutil
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from datetime import datetime


def create_output_dirs(model_name, epochs, base_output_dir="outputs", enable_logs=True):
    """
    åˆ›å»ºè®­ç»ƒè¾“å‡ºç›®å½•ç»“æ„
    
    æŒ‰ç…§æ–°çš„ä¸“ä¸šç»“æ„ç»„ç»‡:
    - weights/: æ¨¡å‹æ–‡ä»¶ (best.pt, last.pt, epoch*.pt)
    - logs/: è¿‡ç¨‹æ€§æ–‡ä»¶ (è®­ç»ƒæŒ‡æ ‡ã€è®°å½•å›¾ç‰‡)
    - analysis/: ç»“æœåˆ†æ (è¯„ä¼°æŠ¥å‘Šã€åˆ†æå›¾è¡¨)
    - meta/: è®­ç»ƒåŸºæœ¬æƒ…å†µ (é…ç½®ã€æ•°æ®é›†ä¿¡æ¯)
    
    Args:
        model_name (str): æ¨¡å‹åç§°
        epochs (int): è®­ç»ƒè½®æ•°
        base_output_dir (str): åŸºç¡€è¾“å‡ºç›®å½•
        enable_logs (bool): æ˜¯å¦å¯ç”¨æ—¥å¿—ç›®å½•
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰ç›®å½•è·¯å¾„çš„å­—å…¸
    """
    timestamp = datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
    base_dir = os.path.join(base_output_dir, f"train_{model_name}_{epochs}ep_{timestamp}")
    
    # åˆ›å»ºå››ä¸ªä¸»è¦ç›®å½•
    dirs = {
        'base': base_dir,
        'weights': os.path.join(base_dir, "weights"),
        'logs': os.path.join(base_dir, "logs"),
        'logs_records': os.path.join(base_dir, "logs", "records"),
        'analysis': os.path.join(base_dir, "analysis"), 
        'meta': os.path.join(base_dir, "meta")
    }
    
    # åˆ›å»ºæ‰€æœ‰ç›®å½•
    for dir_path in dirs.values():
        os.makedirs(dir_path, exist_ok=True)
    
    return dirs


def validate_files(model_file, data_yaml):
    """
    éªŒè¯å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    
    Args:
        model_file (str): æ¨¡å‹æ–‡ä»¶è·¯å¾„ (YOLOv8ä¼šè‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹)
        data_yaml (str): æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        
    Raises:
        FileNotFoundError: å½“æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    # YOLOv8æ¨¡å‹æ–‡ä»¶ä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œä¸éœ€è¦éªŒè¯
    # åªéªŒè¯æ•°æ®é›†é…ç½®æ–‡ä»¶
    if not os.path.isfile(data_yaml):
        raise FileNotFoundError(f"æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    if os.path.isfile(model_file):
        print(f"ğŸ“¦ ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {model_file}")
    else:
        print(f"ğŸ“¦ æ¨¡å‹å°†è‡ªåŠ¨ä¸‹è½½: {model_file}")


def ensure_model_extension(model_name):
    """
    ç¡®ä¿æ¨¡å‹åç§°åŒ…å«.ptæ‰©å±•åï¼Œå¹¶è¿”å›modelsæ–‡ä»¶å¤¹ä¸­çš„å®Œæ•´è·¯å¾„
    
    Args:
        model_name (str): æ¨¡å‹åç§°
        
    Returns:
        str: modelsæ–‡ä»¶å¤¹ä¸­çš„å®Œæ•´æ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿æ¨¡å‹åæœ‰.ptæ‰©å±•å
    if not model_name.endswith('.pt'):
        model_name = model_name + '.pt'
    
    # è¿”å›modelsæ–‡ä»¶å¤¹ä¸­çš„è·¯å¾„
    models_dir = os.path.join(os.getcwd(), 'models')
    os.makedirs(models_dir, exist_ok=True)
    return os.path.join(models_dir, model_name)


def reorganize_training_outputs(yolo_weights_dir, dirs, class_names):
    """
    é‡æ–°ç»„ç»‡è®­ç»ƒè¾“å‡ºæ–‡ä»¶åˆ°æ–°çš„ç›®å½•ç»“æ„
    
    Args:
        yolo_weights_dir (str): YOLOv8åŸå§‹weightsç›®å½•è·¯å¾„
        dirs (dict): æ–°çš„ç›®å½•ç»“æ„å­—å…¸
        class_names (list): ç±»åˆ«åç§°åˆ—è¡¨
    """
    print("ğŸ”„ æ­£åœ¨é‡æ–°ç»„ç»‡è¾“å‡ºæ–‡ä»¶...")
    
    try:
        # 1. ç§»åŠ¨æ¨¡å‹æ–‡ä»¶åˆ° weights/
        weights_subdir = os.path.join(yolo_weights_dir, 'weights')
        if os.path.exists(weights_subdir):
            for pt_file in ['best.pt', 'last.pt']:
                src = os.path.join(weights_subdir, pt_file)
                dst = os.path.join(dirs['weights'], pt_file)
                if os.path.exists(src):
                    shutil.move(src, dst)
            
            # ç§»åŠ¨epochæ–‡ä»¶
            for file in os.listdir(weights_subdir):
                if file.startswith('epoch') and file.endswith('.pt'):
                    src = os.path.join(weights_subdir, file)
                    dst = os.path.join(dirs['weights'], file)
                    shutil.move(src, dst)
        
        # 2. ç§»åŠ¨è®­ç»ƒè®°å½•å›¾ç‰‡åˆ° logs/records/
        record_files = [
            'train_batch0.jpg', 'train_batch1.jpg', 'train_batch2.jpg',
            'val_batch0_labels.jpg', 'val_batch0_pred.jpg',
            'val_batch1_labels.jpg', 'val_batch1_pred.jpg', 
            'val_batch2_labels.jpg', 'val_batch2_pred.jpg'
        ]
        
        for file in record_files:
            src = os.path.join(yolo_weights_dir, file)
            dst = os.path.join(dirs['logs_records'], file)
            if os.path.exists(src):
                shutil.move(src, dst)
        
        # 3. ç§»åŠ¨åˆ†ææ–‡ä»¶åˆ° analysis/
        analysis_files = [
            'BoxF1_curve.png', 'BoxPR_curve.png', 'BoxP_curve.png', 'BoxR_curve.png',
            'confusion_matrix.png', 'confusion_matrix_normalized.png'
        ]
        
        for file in analysis_files:
            src = os.path.join(yolo_weights_dir, file)
            dst = os.path.join(dirs['analysis'], file)
            if os.path.exists(src):
                shutil.move(src, dst)
        
        # 4. ç§»åŠ¨metaæ–‡ä»¶åˆ° meta/
        meta_files = ['args.yaml', 'labels.jpg', 'labels_correlogram.jpg']
        
        for file in meta_files:
            src = os.path.join(yolo_weights_dir, file)
            dst = os.path.join(dirs['meta'], file)
            if os.path.exists(src):
                shutil.move(src, dst)
        
        # 5. åˆå¹¶è®­ç»ƒæŒ‡æ ‡æ–‡ä»¶
        merge_training_metrics(yolo_weights_dir, dirs)
        
        # 6. åˆå¹¶è®­ç»ƒæŒ‡æ ‡å›¾ç‰‡
        merge_training_images(dirs)
        
        # 7. åˆ›å»ºåˆ†æREADMEæ–‡æ¡£
        create_analysis_readme(dirs, class_names)
        
        # 8. æ¸…ç†ç©ºçš„åµŒå¥—weightsç›®å½•
        nested_weights = os.path.join(yolo_weights_dir, 'weights')
        if os.path.exists(nested_weights) and not os.listdir(nested_weights):
            os.rmdir(nested_weights)
            
        print("âœ… è¾“å‡ºæ–‡ä»¶é‡ç»„ç»‡å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æ–‡ä»¶é‡ç»„ç»‡å¤±è´¥: {e}")


def merge_training_metrics(yolo_weights_dir, dirs):
    """åˆå¹¶è®­ç»ƒæŒ‡æ ‡CSVæ–‡ä»¶"""
    try:
        results_csv = os.path.join(yolo_weights_dir, 'results.csv')
        complete_csv = os.path.join(dirs['base'], 'logs', 'complete_evaluation_metrics.csv')
        output_csv = os.path.join(dirs['logs'], 'training_metrics.csv')
        
        # è¯»å–YOLOv8çš„results.csv
        results_data = None
        if os.path.exists(results_csv):
            results_data = pd.read_csv(results_csv)
            # æ¸…ç†åˆ—åçš„ç©ºæ ¼
            results_data.columns = results_data.columns.str.strip()
        
        # è¯»å–æˆ‘ä»¬çš„complete_evaluation_metrics.csv  
        complete_data = None
        if os.path.exists(complete_csv):
            complete_data = pd.read_csv(complete_csv)
        
        # åˆå¹¶æ•°æ®å¹¶ä¿å­˜
        if results_data is not None:
            results_data.to_csv(output_csv, index=False)
            if complete_data is not None:
                # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ åˆ†éš”å’Œå®Œæ•´è¯„ä¼°æ•°æ®
                with open(output_csv, 'a', encoding='utf-8') as f:
                    f.write('\n\n# Complete Evaluation Metrics\n')
                complete_data.to_csv(output_csv, mode='a', index=False)
        
        # åˆ é™¤åŸå§‹æ–‡ä»¶
        for file in [results_csv, complete_csv]:
            if os.path.exists(file):
                os.remove(file)
                
    except Exception as e:
        print(f"âš ï¸ åˆå¹¶è®­ç»ƒæŒ‡æ ‡å¤±è´¥: {e}")


def merge_training_images(dirs):
    """å¤„ç†è®­ç»ƒæŒ‡æ ‡å›¾ç‰‡ - ç°åœ¨ç›´æ¥ä½¿ç”¨ç»Ÿä¸€ç”Ÿæˆçš„å›¾ç‰‡ï¼Œæ— éœ€åˆå¹¶"""
    try:
        # ç°åœ¨ç›´æ¥ä½¿ç”¨ç»Ÿä¸€ç”Ÿæˆçš„training_metrics.png
        source_img = os.path.join(dirs['base'], 'logs', 'training_metrics.png')
        target_img = os.path.join(dirs['logs'], 'training_metrics.png')
        
        # å¦‚æœæºå›¾ç‰‡å­˜åœ¨ä¸”ä¸ç›®æ ‡ä¸æ˜¯åŒä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ™ç§»åŠ¨
        if os.path.exists(source_img) and source_img != target_img:
            import shutil
            shutil.move(source_img, target_img)
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§çš„åˆ†ç¦»å›¾ç‰‡æ–‡ä»¶
        old_files = [
            os.path.join(dirs['base'], 'logs', 'training_analysis.png'),
            os.path.join(dirs['base'], 'logs', 'enhanced_metrics_analysis.png')
        ]
        for old_file in old_files:
            if os.path.exists(old_file):
                os.remove(old_file)
        
    except Exception as e:
        print(f"âš ï¸ å¤„ç†è®­ç»ƒå›¾ç‰‡å¤±è´¥: {e}")


def create_analysis_readme(dirs, class_names):
    """åˆ›å»ºåˆ†æREADMEæ–‡æ¡£"""
    try:
        # è¯»å–åŸå§‹æŠ¥å‘Š
        metrics_report = os.path.join(dirs['base'], 'logs', 'metrics_report.md')
        per_class_report = os.path.join(dirs['base'], 'logs', 'per_class_report.md')
        output_readme = os.path.join(dirs['analysis'], 'README.md')
        
        # ç§»åŠ¨per_class_metrics.pngåˆ°analysisç›®å½•
        per_class_img = os.path.join(dirs['base'], 'logs', 'per_class_metrics.png')
        if os.path.exists(per_class_img):
            shutil.move(per_class_img, os.path.join(dirs['analysis'], 'per_class_metrics.png'))
        
        # åˆ›å»ºREADMEå†…å®¹
        readme_content = f"""# è®­ç»ƒç»“æœåˆ†ææŠ¥å‘Š

## å¦‚ä½•å¾—åˆ°çš„è®­ç»ƒç»“æœåˆ†æ

æœ¬åˆ†æåŸºäºYOLOv8è®­ç»ƒå®Œæˆååœ¨éªŒè¯é›†ä¸Šçš„æœ€ç»ˆè¯„ä¼°ç»“æœã€‚å…·ä½“æ¥æºï¼š

### æŒ‡æ ‡è®¡ç®—æ–¹æ³•

1. **æ•´ä½“æŒ‡æ ‡** (ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1-Scoreã€mAPç­‰)
   - æ¥æºï¼šè®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨æœ€ä½³æ¨¡å‹(`best.pt`)åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼°
   - è®¡ç®—æ–¹å¼ï¼šåŸºäºæ‰€æœ‰ç±»åˆ«çš„å¹³å‡å€¼
   - æ•°æ®æ–‡ä»¶ï¼š`../logs/training_metrics.csv`

2. **æ¯ç±»åˆ«æŒ‡æ ‡**
   - æ¥æºï¼šä½¿ç”¨æ¯ç±»åˆ«è¯„ä¼°å™¨å¯¹æœ€ä½³æ¨¡å‹è¿›è¡Œè¯¦ç»†åˆ†æ
   - åŒ…æ‹¬æ¯ä¸ªç±»åˆ«çš„ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1-Scoreã€AP@0.5ç­‰
   - å¯è§†åŒ–ï¼š`per_class_metrics.png`

3. **æ··æ·†çŸ©é˜µä¸æ›²çº¿åˆ†æ**
   - åŸºäºéªŒè¯é›†é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾çš„å¯¹æ¯”
   - åŒ…æ‹¬F1æ›²çº¿ã€PRæ›²çº¿ã€ç²¾ç¡®ç‡æ›²çº¿ã€å¬å›ç‡æ›²çº¿
   - åæ˜ æ¨¡å‹åœ¨ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„è¡¨ç°

## è®­ç»ƒç»“æœç»¼åˆåˆ†æ

"""
        
        # è¯»å–å¹¶æ•´åˆåŸå§‹æŠ¥å‘Šå†…å®¹
        if os.path.exists(metrics_report):
            with open(metrics_report, 'r', encoding='utf-8') as f:
                content = f.read()
                # ç§»é™¤æ ‡é¢˜ï¼Œåªä¿ç•™å†…å®¹
                content = content.replace('# YOLOv8 ç‰™é½¿æ£€æµ‹æ¨¡å‹è®­ç»ƒæŠ¥å‘Š', '').strip()
                readme_content += content + "\n\n"
        
        if os.path.exists(per_class_report):
            with open(per_class_report, 'r', encoding='utf-8') as f:
                content = f.read()
                # ç§»é™¤æ ‡é¢˜ï¼Œåªä¿ç•™å†…å®¹
                content = content.replace('# æ¯ç±»åˆ«è¯¦ç»†æŒ‡æ ‡æŠ¥å‘Š', '### æ¯ç±»åˆ«è¯¦ç»†åˆ†æ').strip()
                readme_content += content + "\n\n"
        
        # æ·»åŠ æ–‡ä»¶è¯´æ˜
        readme_content += f"""
## åˆ†ææ–‡ä»¶è¯´æ˜

### å›¾è¡¨æ–‡ä»¶
- `per_class_metrics.png` - å„ç±»åˆ«æŒ‡æ ‡å¯¹æ¯”å›¾
- `BoxF1_curve.png` - F1-Scoreæ›²çº¿ (ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼)
- `BoxPR_curve.png` - ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ 
- `BoxP_curve.png` - ç²¾ç¡®ç‡æ›²çº¿
- `BoxR_curve.png` - å¬å›ç‡æ›²çº¿
- `confusion_matrix.png` - æ··æ·†çŸ©é˜µ (åŸå§‹æ•°é‡)
- `confusion_matrix_normalized.png` - æ ‡å‡†åŒ–æ··æ·†çŸ©é˜µ (ç™¾åˆ†æ¯”)

### ç›¸å…³æ•°æ®
- è®­ç»ƒè¿‡ç¨‹æ•°æ®ï¼š`../logs/training_metrics.csv`
- è®­ç»ƒè¿‡ç¨‹å›¾è¡¨ï¼š`../logs/training_metrics.png`
- æ¨¡å‹æ–‡ä»¶ï¼š`../weights/best.pt`

---
*åˆ†ææŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
        
        # ä¿å­˜README
        with open(output_readme, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        # åˆ é™¤åŸå§‹æŠ¥å‘Šæ–‡ä»¶
        for file in [metrics_report, per_class_report]:
            if os.path.exists(file):
                os.remove(file)
                
    except Exception as e:
        print(f"âš ï¸ åˆ›å»ºåˆ†æREADMEå¤±è´¥: {e}")
