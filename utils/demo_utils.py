#!/usr/bin/env python3
"""
YOLOv8ç‰™é½¿æ£€æµ‹æ¼”ç¤ºå·¥å…·ç±»
æä¾›å•å›¾æ£€æµ‹ã€å¯è§†åŒ–å¯¹æ¯”ã€IoUåˆ†æç­‰åŠŸèƒ½
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib import rcParams
from ultralytics import YOLO
import yaml
from pathlib import Path
from typing import List, Dict, Tuple, Optional


def find_data_yaml(image_path: str) -> str:
    """
    æ ¹æ®å›¾ç‰‡è·¯å¾„è‡ªåŠ¨æŸ¥æ‰¾å¯¹åº”çš„data.yamlæ–‡ä»¶
    
    Args:
        image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        
    Returns:
        data.yamlæ–‡ä»¶è·¯å¾„
    """
    from pathlib import Path
    
    image_path = Path(image_path)
    
    # å‘ä¸ŠæŸ¥æ‰¾åŒ…å«data.yamlçš„ç›®å½•
    for parent in image_path.parents:
        data_yaml_path = parent / "data.yaml"
        if data_yaml_path.exists():
            return str(data_yaml_path)
    
    raise FileNotFoundError(f"æœªæ‰¾åˆ°data.yamlæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡è·¯å¾„: {image_path}")


class DentalDetectionDemo:
    """ç‰™é½¿æ£€æµ‹æ¼”ç¤ºç±»"""
    
    def __init__(self, model_path: str, data_yaml: str):
        """
        åˆå§‹åŒ–æ¼”ç¤ºç±»
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            data_yaml: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.model_path = model_path
        self.data_yaml = data_yaml
        self.model = None
        self.class_names = []
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“å’Œé¢œè‰²
        rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        rcParams['axes.unicode_minus'] = False
        
        self.GT_COLOR = 'lime'
        self.PRED_COLOR = 'red'
        self.GT_TEXT_COLOR = 'darkgreen' 
        self.PRED_TEXT_COLOR = 'darkred'
        
        self._load_model_and_config()
    
    def _load_model_and_config(self):
        """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        if not os.path.exists(self.data_yaml):
            raise FileNotFoundError(f"æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_yaml}")
        
        # åŠ è½½æ¨¡å‹
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        self.model = YOLO(self.model_path)
        print("æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # è¯»å–ç±»åˆ«åç§°
        with open(self.data_yaml, 'r', encoding='utf-8') as f:
            data_config = yaml.safe_load(f)
            self.class_names = data_config.get('names', ['Caries', 'Cavity', 'Crack', 'Tooth'])
        
        print(f"ç±»åˆ«åç§°: {self.class_names}")
    
    def get_available_images(self, test_dir: str, max_count: int = 20) -> List[Path]:
        """
        è·å–æµ‹è¯•å›¾ç‰‡åˆ—è¡¨
        
        Args:
            test_dir: æµ‹è¯•å›¾ç‰‡ç›®å½•
            max_count: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        """
        if not os.path.exists(test_dir):
            raise FileNotFoundError(f"æµ‹è¯•å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        
        images = []
        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            images.extend(Path(test_dir).glob(f'*{ext}'))
            images.extend(Path(test_dir).glob(f'*{ext.upper()}'))
        
        return sorted(images)[:max_count]
    
    def load_ground_truth_labels(self, label_path: str) -> List[List[float]]:
        """
        åŠ è½½çœŸå®æ ‡ç­¾
        
        Args:
            label_path: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ ‡ç­¾åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º[class_id, x_center, y_center, width, height]
        """
        labels = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        labels.append([float(x) for x in parts])
        return labels
    
    def denormalize_bbox(self, bbox: List[float], img_width: int, img_height: int) -> Tuple[int, int, int, int]:
        """
        å°†YOLOæ ¼å¼çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†è½¬æ¢ä¸ºåƒç´ åæ ‡
        
        Args:
            bbox: [x_center, y_center, width, height] (å½’ä¸€åŒ–)
            img_width: å›¾åƒå®½åº¦
            img_height: å›¾åƒé«˜åº¦
            
        Returns:
            (x_min, y_min, x_max, y_max) åƒç´ åæ ‡
        """
        x_center, y_center, width, height = bbox
        x_center *= img_width
        y_center *= img_height
        width *= img_width
        height *= img_height
        
        x_min = x_center - width / 2
        y_min = y_center - height / 2
        x_max = x_center + width / 2
        y_max = y_center + height / 2
        
        return int(x_min), int(y_min), int(x_max), int(y_max)
    
    def predict_image(self, image_path: str, conf_threshold: float = 0.1) -> List[Dict]:
        """
        å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = self.model.predict(image_path, verbose=False)
        predictions = []
        
        if results and len(results) > 0 and results[0].boxes is not None:
            boxes = results[0].boxes
            for box in boxes:
                x_min, y_min, x_max, y_max = box.xyxy[0].cpu().numpy()
                confidence = box.conf[0].cpu().numpy()
                class_id = int(box.cls[0].cpu().numpy())
                
                if confidence >= conf_threshold:
                    predictions.append({
                        'bbox': [x_min, y_min, x_max, y_max],
                        'confidence': confidence,
                        'class_id': class_id,
                        'class_name': self.class_names[class_id] if class_id < len(self.class_names) else f'Class{class_id}'
                    })
        
        return predictions
    
    def calculate_iou(self, box1: List[float], box2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU"""
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2
        
        # è®¡ç®—äº¤é›†
        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)
        
        if inter_x_min >= inter_x_max or inter_y_min >= inter_y_max:
            return 0.0
        
        inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
        box1_area = (x1_max - x1_min) * (y1_max - y1_min)
        box2_area = (x2_max - x2_min) * (y2_max - y2_min)
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area if union_area > 0 else 0.0
    
    def analyze_detection_results(self, gt_labels: List[List[float]], predictions: List[Dict], 
                                img_width: int, img_height: int, iou_threshold: float = 0.5) -> Dict:
        """
        åˆ†ææ£€æµ‹ç»“æœ
        
        Args:
            gt_labels: çœŸå®æ ‡ç­¾
            predictions: é¢„æµ‹ç»“æœ
            img_width: å›¾åƒå®½åº¦
            img_height: å›¾åƒé«˜åº¦
            iou_threshold: IoUé˜ˆå€¼
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # è½¬æ¢çœŸå®æ ‡ç­¾ä¸ºåƒç´ åæ ‡
        gt_boxes = []
        for label in gt_labels:
            class_id, x_center, y_center, width, height = label
            x_min, y_min, x_max, y_max = self.denormalize_bbox(
                [x_center, y_center, width, height], img_width, img_height
            )
            gt_boxes.append((x_min, y_min, x_max, y_max))
        
        matched_gt = set()
        matched_pred = set()
        matches = []
        
        for i, gt_box in enumerate(gt_boxes):
            best_iou = 0
            best_pred_idx = -1
            
            for j, pred in enumerate(predictions):
                pred_box = pred['bbox']
                iou = self.calculate_iou(gt_box, pred_box)
                
                if iou > best_iou:
                    best_iou = iou
                    best_pred_idx = j
            
            if best_iou > iou_threshold:
                matched_gt.add(i)
                matched_pred.add(best_pred_idx)
                gt_class = self.class_names[int(gt_labels[i][0])]
                pred_class = predictions[best_pred_idx]['class_name']
                conf = predictions[best_pred_idx]['confidence']
                
                matches.append({
                    'gt_idx': i,
                    'pred_idx': best_pred_idx,
                    'gt_class': gt_class,
                    'pred_class': pred_class,
                    'confidence': conf,
                    'iou': best_iou
                })
        
        return {
            'matches': matches,
            'matched_gt_count': len(matched_gt),
            'matched_pred_count': len(matched_pred),
            'total_gt': len(gt_labels),
            'total_pred': len(predictions),
            'false_negatives': len(gt_labels) - len(matched_gt),
            'false_positives': len(predictions) - len(matched_pred)
        }
    
    def visualize_detection(self, image_path: str, save_path: Optional[str] = None) -> Dict:
        """
        å®Œæ•´çš„æ£€æµ‹å¯è§†åŒ–æµç¨‹
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ£€æµ‹åˆ†æç»“æœ
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        img_height, img_width = image.shape[:2]
        
        # åŠ è½½çœŸå®æ ‡ç­¾
        image_name = os.path.splitext(os.path.basename(image_path))[0]
        label_dir = os.path.dirname(image_path).replace('images', 'labels')
        label_path = os.path.join(label_dir, f"{image_name}.txt")
        gt_labels = self.load_ground_truth_labels(label_path)
        
        # æ¨¡å‹é¢„æµ‹
        predictions = self.predict_image(image_path)
        
        # åˆ†æç»“æœ
        analysis = self.analyze_detection_results(gt_labels, predictions, img_width, img_height)
        
        # å¯è§†åŒ–
        self._plot_comparison(image, gt_labels, predictions, img_width, img_height, analysis)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³: {save_path}")
        
        plt.show()
        
        return analysis
    
    def _plot_comparison(self, image: np.ndarray, gt_labels: List[List[float]], 
                        predictions: List[Dict], img_width: int, img_height: int, analysis: Dict):
        """ç»˜åˆ¶å¯¹æ¯”å›¾"""
        fig, axes = plt.subplots(1, 3, figsize=(24, 8))
        
        TEXT_BG = dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9, edgecolor='black')
        
        # 1. åŸå§‹å›¾åƒ
        axes[0].imshow(image)
        axes[0].set_title('åŸå§‹å›¾åƒ', fontsize=16, fontweight='bold', pad=20)
        axes[0].axis('off')
        
        # 2. çœŸå®æ ‡ç­¾
        axes[1].imshow(image)
        axes[1].set_title(f'çœŸå®æ ‡ç­¾ ({len(gt_labels)} ä¸ª)', fontsize=16, fontweight='bold', 
                         pad=20, color='darkgreen')
        axes[1].axis('off')
        
        for i, label in enumerate(gt_labels):
            class_id, x_center, y_center, width, height = label
            x_min, y_min, x_max, y_max = self.denormalize_bbox(
                [x_center, y_center, width, height], img_width, img_height
            )
            
            rect = patches.Rectangle(
                (x_min, y_min), x_max - x_min, y_max - y_min,
                linewidth=3, edgecolor=self.GT_COLOR, facecolor='none', alpha=0.8
            )
            axes[1].add_patch(rect)
            
            class_name = self.class_names[int(class_id)] if int(class_id) < len(self.class_names) else f'Class{int(class_id)}'
            axes[1].text(x_min, y_min - 10, f'GT-{i+1}: {class_name}', 
                       fontsize=11, color=self.GT_TEXT_COLOR, fontweight='bold', bbox=TEXT_BG)
        
        # 3. é¢„æµ‹ç»“æœ
        axes[2].imshow(image)
        axes[2].set_title(f'é¢„æµ‹ç»“æœ ({len(predictions)} ä¸ª)', fontsize=16, fontweight='bold',
                         pad=20, color='darkred')
        axes[2].axis('off')
        
        for i, pred in enumerate(predictions):
            x_min, y_min, x_max, y_max = pred['bbox']
            
            rect = patches.Rectangle(
                (x_min, y_min), x_max - x_min, y_max - y_min,
                linewidth=3, edgecolor=self.PRED_COLOR, facecolor='none', alpha=0.8
            )
            axes[2].add_patch(rect)
            
            axes[2].text(x_min, y_min - 10, 
                       f"Pred-{i+1}: {pred['class_name']} ({pred['confidence']:.2f})", 
                       fontsize=11, color=self.PRED_TEXT_COLOR, fontweight='bold', bbox=TEXT_BG)
        
        plt.tight_layout()
        
        # æ‰“å°åˆ†æç»“æœ
        self._print_analysis(analysis)
    
    def _print_analysis(self, analysis: Dict):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\n" + "="*70)
        print("æ£€æµ‹ç»“æœåˆ†æ:")
        print("="*70)
        print(f"çœŸå®æ ‡ç­¾: {analysis['total_gt']} ä¸ª")
        print(f"é¢„æµ‹ç»“æœ: {analysis['total_pred']} ä¸ª")
        print(f"æˆåŠŸåŒ¹é…: {analysis['matched_gt_count']} ä¸ª")
        print(f"æ¼æ£€ (FN): {analysis['false_negatives']} ä¸ª") 
        print(f"è¯¯æ£€ (FP): {analysis['false_positives']} ä¸ª")
        
        if analysis['matches']:
            print(f"\nåŒ¹é…è¯¦æƒ…:")
            for match in analysis['matches']:
                print(f"   GT-{match['gt_idx']+1} ({match['gt_class']}) <-> "
                      f"Pred-{match['pred_idx']+1} ({match['pred_class']}, "
                      f"{match['confidence']:.2f}) | IoU: {match['iou']:.3f}")
    
    def predict_only(self, image_path: str):
        """ä»…è¿›è¡Œé¢„æµ‹ï¼Œä¸éœ€è¦çœŸå®æ ‡ç­¾å¯¹æ¯”"""
        image_path = Path(image_path)
        
        # åŠ è½½å›¾ç‰‡
        image = cv2.imread(str(image_path))
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # æ¨¡å‹é¢„æµ‹
        predictions = self.predict_image(str(image_path))
        
        print(f"\né¢„æµ‹ç»“æœ: æ£€æµ‹åˆ° {len(predictions)} ä¸ªç›®æ ‡")
        
        # å¯è§†åŒ–é¢„æµ‹ç»“æœ
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        
        ax.imshow(image_rgb)
        ax.set_title(f'é¢„æµ‹ç»“æœ ({len(predictions)} ä¸ª)', fontsize=18, fontweight='bold',
                    pad=20, color='darkred')
        ax.axis('off')
        
        TEXT_BG = dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8)
        
        for i, pred in enumerate(predictions):
            x_min, y_min, x_max, y_max = pred['bbox']
            
            # ç»˜åˆ¶é¢„æµ‹æ¡†
            rect = patches.Rectangle(
                (x_min, y_min), x_max - x_min, y_max - y_min,
                linewidth=3, edgecolor=self.PRED_COLOR, facecolor='none', alpha=0.8
            )
            ax.add_patch(rect)
            
            # æ·»åŠ æ ‡ç­¾
            ax.text(x_min, y_min - 10, 
                   f"Pred-{i+1}: {pred['class_name']} ({pred['confidence']:.2f})", 
                   fontsize=12, color=self.PRED_TEXT_COLOR, fontweight='bold', bbox=TEXT_BG)
        
        plt.tight_layout()
        plt.show()
        
        # æ‰“å°é¢„æµ‹è¯¦æƒ…
        if predictions:
            print("\né¢„æµ‹è¯¦æƒ…:")
            for i, pred in enumerate(predictions):
                print(f"   Pred-{i+1}: {pred['class_name']} (ç½®ä¿¡åº¦: {pred['confidence']:.2f})")
        else:
            print("æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
    
    def show_image_selector(self, test_dir: str):
        """æ˜¾ç¤ºå›¾ç‰‡é€‰æ‹©å™¨"""
        images = self.get_available_images(test_dir)
        if not images:
            print(f"é”™è¯¯: åœ¨ {test_dir} ä¸­æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
            return []
        
        print(f"å¯é€‰æ‹©çš„æµ‹è¯•å›¾ç‰‡ (å…± {len(images)} å¼ ):")
        for i, img_path in enumerate(images):
            print(f"   {i+1:2d}. {img_path.name}")
        
        return images
